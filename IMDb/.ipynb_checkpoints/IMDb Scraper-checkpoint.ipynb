{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb2ce90",
   "metadata": {},
   "source": [
    "# Ugwumsi Egbuna\n",
    "## Data Scientist\n",
    "## IMDb Web Scraper\n",
    "## March 11, 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c405e0",
   "metadata": {},
   "source": [
    "# This script scrapes data on movies from January 2000 to September 2022\n",
    "## It captures the following data points\n",
    "1. Movie Title\n",
    "2. Release Date\n",
    "3. Rating\n",
    "4. Total Number of votes in the rating\n",
    "5. Award Nomination Wins\n",
    "6. Country of Origin\n",
    "7. Directors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc9615",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "418635c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928be6b3",
   "metadata": {},
   "source": [
    "Call Web Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22744585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up driver to automatically load chrome browser\n",
    "my_driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404b8ca",
   "metadata": {},
   "source": [
    "Navigate to the search results page on the IMDb website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5059c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get search result page\n",
    "feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\n",
    "\n",
    "#Open search result page\n",
    "my_driver.get(feature_films)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e8ba2",
   "metadata": {},
   "source": [
    "## The following steps were taken in this scraping exercise;\n",
    "1. Install and setup a chrome WebDriver, the lauch the chrome browser window.\n",
    "2. Navigate to the search results page.\n",
    "3. Extracts the movie titles and Movie Links on each page.\n",
    "4. Check if there are no more movies on the page and we need to go the next page to cotinue scraping.\n",
    "5. Loop through the url list from the movies gotten in 4 up.\n",
    "6. Navigate to the url in the browser, and get all the relevant details from there such as Directors, Award Wins, Ratings etc.\n",
    "7. Add them to their respective lists.\n",
    "8. Create a csv file in th epresent working directory and write all the data to the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97582174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "0\n",
      "Hello\n",
      "1\n",
      "Hello\n",
      "2\n",
      "Hello\n",
      "3\n",
      "Hello\n",
      "4\n",
      "Hello\n",
      "5\n",
      "Hello\n",
      "6\n",
      "Hello\n",
      "7\n",
      "Hello\n",
      "8\n",
      "Hello\n",
      "9\n",
      "Hello\n",
      "10\n",
      "Hello\n",
      "11\n",
      "Hello\n",
      "12\n",
      "Hello\n",
      "13\n",
      "Hello\n",
      "14\n",
      "Hello\n",
      "15\n",
      "Hello\n",
      "16\n",
      "Hello\n",
      "17\n",
      "Hello\n",
      "18\n",
      "Hello\n",
      "19\n",
      "Hello\n",
      "20\n",
      "Hello\n",
      "21\n",
      "Hello\n",
      "22\n",
      "Hello\n",
      "23\n",
      "Hello\n",
      "24\n",
      "Hello\n",
      "25\n",
      "Hello\n",
      "26\n",
      "Hello\n",
      "27\n",
      "Hello\n",
      "28\n",
      "Hello\n",
      "29\n",
      "Hello\n",
      "30\n",
      "Hello\n",
      "31\n",
      "Hello\n",
      "32\n",
      "Hello\n",
      "33\n",
      "Hello\n",
      "34\n",
      "Hello\n",
      "35\n",
      "Hello\n",
      "36\n",
      "Hello\n",
      "37\n",
      "Hello\n",
      "38\n",
      "Hello\n",
      "39\n",
      "Hello\n",
      "40\n",
      "Hello\n",
      "41\n",
      "Hello\n",
      "42\n",
      "Hello\n",
      "43\n",
      "Hello\n",
      "44\n",
      "Hello\n",
      "45\n",
      "Hello\n",
      "46\n",
      "Hello\n",
      "47\n",
      "Hello\n",
      "48\n",
      "Hello\n",
      "49\n",
      "Hello\n",
      "50\n",
      "Hello\n",
      "51\n",
      "Hello\n",
      "52\n",
      "Hello\n",
      "53\n",
      "Hello\n",
      "54\n",
      "Hello\n",
      "55\n",
      "Hello\n",
      "56\n",
      "Hello\n",
      "57\n",
      "Hello\n",
      "58\n",
      "Hello\n",
      "59\n",
      "Hello\n",
      "60\n",
      "Hello\n",
      "61\n",
      "Hello\n",
      "62\n",
      "Hello\n",
      "63\n",
      "Hello\n",
      "64\n",
      "Hello\n",
      "65\n",
      "Hello\n",
      "66\n",
      "Hello\n",
      "67\n",
      "Hello\n",
      "68\n",
      "Hello\n",
      "69\n",
      "Hello\n",
      "70\n",
      "Hello\n",
      "71\n",
      "Hello\n",
      "72\n",
      "Hello\n",
      "73\n",
      "Hello\n",
      "74\n",
      "Hello\n",
      "75\n",
      "Hello\n",
      "76\n",
      "Hello\n",
      "77\n",
      "Hello\n",
      "78\n",
      "Hello\n",
      "79\n",
      "Hello\n",
      "80\n",
      "Hello\n",
      "81\n",
      "Hello\n",
      "82\n",
      "Hello\n",
      "83\n",
      "Hello\n",
      "84\n",
      "Hello\n",
      "85\n",
      "Hello\n",
      "86\n",
      "Hello\n",
      "87\n",
      "Hello\n",
      "88\n",
      "Hello\n",
      "89\n",
      "Hello\n",
      "90\n",
      "Hello\n",
      "91\n",
      "Hello\n",
      "92\n",
      "Hello\n",
      "93\n",
      "Hello\n",
      "94\n",
      "Hello\n",
      "95\n",
      "Hello\n",
      "96\n",
      "Hello\n",
      "97\n",
      "Hello\n",
      "98\n",
      "Hello\n",
      "99\n",
      "Hello\n",
      "100\n",
      "Hello\n",
      "101\n",
      "Hello\n",
      "102\n",
      "Hello\n",
      "103\n",
      "Hello\n",
      "104\n",
      "Hello\n",
      "105\n",
      "Hello\n",
      "106\n",
      "Hello\n",
      "107\n",
      "Hello\n",
      "108\n",
      "Hello\n",
      "109\n",
      "Hello\n",
      "110\n",
      "Hello\n",
      "111\n",
      "Hello\n",
      "112\n",
      "Hello\n",
      "113\n",
      "Hello\n",
      "114\n",
      "Hello\n",
      "115\n",
      "Hello\n",
      "116\n",
      "Hello\n",
      "117\n",
      "Hello\n",
      "118\n",
      "Hello\n",
      "119\n",
      "Hello\n",
      "120\n",
      "Hello\n",
      "121\n",
      "Hello\n",
      "122\n",
      "Hello\n",
      "123\n",
      "Hello\n",
      "124\n",
      "Hello\n",
      "125\n",
      "Hello\n",
      "126\n",
      "Hello\n",
      "127\n",
      "Hello\n",
      "128\n",
      "Hello\n",
      "129\n",
      "Hello\n",
      "130\n",
      "Hello\n",
      "131\n",
      "Hello\n",
      "132\n",
      "Hello\n",
      "133\n",
      "Hello\n",
      "134\n",
      "Hello\n",
      "135\n",
      "Hello\n",
      "136\n",
      "Hello\n",
      "137\n",
      "Hello\n",
      "138\n",
      "Hello\n",
      "139\n",
      "Hello\n",
      "140\n",
      "Hello\n",
      "141\n",
      "Hello\n",
      "142\n",
      "Hello\n",
      "143\n",
      "Hello\n",
      "144\n",
      "Hello\n",
      "145\n",
      "Hello\n",
      "146\n",
      "Hello\n",
      "147\n",
      "Hello\n",
      "148\n",
      "Hello\n",
      "149\n",
      "Hello\n",
      "150\n",
      "Hello\n",
      "151\n",
      "Hello\n",
      "152\n",
      "Hello\n",
      "153\n",
      "Hello\n",
      "154\n",
      "Hello\n",
      "155\n",
      "Hello\n",
      "156\n",
      "Hello\n",
      "157\n",
      "Hello\n",
      "158\n",
      "Hello\n",
      "159\n",
      "Hello\n",
      "160\n",
      "Hello\n",
      "161\n",
      "Hello\n",
      "162\n",
      "Hello\n",
      "163\n",
      "Hello\n",
      "164\n",
      "Hello\n",
      "165\n",
      "Hello\n",
      "166\n",
      "Hello\n",
      "167\n",
      "Hello\n",
      "168\n",
      "Hello\n",
      "169\n",
      "Hello\n",
      "170\n",
      "Hello\n",
      "171\n",
      "Hello\n",
      "172\n",
      "Hello\n",
      "173\n",
      "Hello\n",
      "174\n",
      "Hello\n",
      "175\n",
      "Hello\n",
      "176\n",
      "Hello\n",
      "177\n",
      "Hello\n",
      "178\n",
      "Hello\n",
      "179\n",
      "Hello\n",
      "180\n",
      "Hello\n",
      "181\n",
      "Hello\n",
      "182\n",
      "Hello\n",
      "183\n",
      "Hello\n",
      "184\n",
      "Hello\n",
      "185\n",
      "Hello\n",
      "186\n",
      "Hello\n",
      "187\n",
      "Hello\n",
      "188\n",
      "Hello\n",
      "189\n",
      "Hello\n",
      "190\n",
      "Hello\n",
      "191\n",
      "Hello\n",
      "192\n",
      "Hello\n",
      "193\n",
      "Hello\n",
      "194\n",
      "Hello\n",
      "195\n",
      "Hello\n",
      "196\n",
      "Hello\n",
      "197\n",
      "Hello\n",
      "198\n",
      "Hello\n",
      "199\n",
      "Hello\n",
      "200\n",
      "Hello\n",
      "201\n",
      "Hello\n",
      "202\n",
      "Hello\n",
      "203\n",
      "Hello\n",
      "204\n",
      "Hello\n",
      "205\n",
      "Hello\n",
      "206\n",
      "Hello\n",
      "207\n",
      "Hello\n",
      "208\n",
      "Hello\n",
      "209\n",
      "Hello\n",
      "210\n",
      "Hello\n",
      "211\n",
      "Hello\n",
      "212\n",
      "Hello\n",
      "213\n",
      "Hello\n",
      "214\n",
      "Hello\n",
      "215\n",
      "Hello\n",
      "216\n",
      "Hello\n",
      "217\n",
      "Hello\n",
      "218\n",
      "Hello\n",
      "219\n",
      "Hello\n",
      "220\n",
      "Hello\n",
      "221\n",
      "Hello\n",
      "222\n",
      "Hello\n",
      "223\n",
      "Hello\n",
      "224\n",
      "Hello\n",
      "225\n",
      "Hello\n",
      "226\n",
      "Hello\n",
      "227\n",
      "Hello\n",
      "228\n",
      "Hello\n",
      "229\n",
      "Hello\n",
      "230\n",
      "Hello\n",
      "231\n",
      "Hello\n",
      "232\n",
      "Hello\n",
      "233\n",
      "Hello\n",
      "234\n",
      "Hello\n",
      "235\n",
      "Hello\n",
      "236\n",
      "Hello\n",
      "237\n",
      "Hello\n",
      "238\n",
      "Hello\n",
      "239\n",
      "Hello\n",
      "240\n",
      "Hello\n",
      "241\n",
      "Hello\n",
      "242\n",
      "Hello\n",
      "243\n",
      "Hello\n",
      "244\n",
      "Hello\n",
      "245\n",
      "Hello\n",
      "246\n",
      "Hello\n",
      "247\n",
      "Hello\n",
      "248\n",
      "Hello\n",
      "249\n",
      "Hello\n",
      "250\n",
      "Hello\n",
      "251\n",
      "Hello\n",
      "252\n",
      "Hello\n",
      "253\n",
      "Hello\n",
      "254\n",
      "Hello\n",
      "255\n",
      "Hello\n",
      "256\n",
      "Hello\n",
      "257\n",
      "Hello\n",
      "258\n",
      "Hello\n",
      "259\n",
      "Hello\n",
      "260\n",
      "Hello\n",
      "261\n",
      "Hello\n",
      "262\n",
      "Hello\n",
      "263\n",
      "Hello\n",
      "264\n",
      "Hello\n",
      "265\n",
      "Hello\n",
      "266\n",
      "Hello\n",
      "267\n",
      "Hello\n",
      "268\n",
      "Hello\n",
      "269\n",
      "Hello\n",
      "270\n",
      "Hello\n",
      "271\n",
      "Hello\n",
      "272\n",
      "Hello\n",
      "273\n",
      "Hello\n",
      "274\n",
      "Hello\n",
      "275\n",
      "Hello\n",
      "276\n",
      "Hello\n",
      "277\n",
      "Hello\n",
      "278\n",
      "Hello\n",
      "279\n",
      "Hello\n",
      "280\n",
      "Hello\n",
      "281\n",
      "Hello\n",
      "282\n",
      "Hello\n",
      "283\n",
      "Hello\n",
      "284\n",
      "Hello\n",
      "285\n",
      "Hello\n",
      "286\n",
      "Hello\n",
      "287\n",
      "Hello\n",
      "288\n",
      "Hello\n",
      "289\n",
      "Hello\n",
      "290\n",
      "Hello\n",
      "291\n",
      "Hello\n",
      "292\n",
      "Hello\n",
      "293\n",
      "Hello\n",
      "294\n",
      "Hello\n",
      "295\n",
      "Hello\n",
      "296\n",
      "Hello\n",
      "297\n",
      "Hello\n",
      "298\n",
      "Hello\n",
      "299\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 194\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m#Run the Scrape Data function\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m \u001b[43mscrape_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [50], line 125\u001b[0m, in \u001b[0;36mscrape_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(url)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m#feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m#webdriver.Chrome(service=Service(ChromeDriverManager().install()))\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[43mmy_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m#Get release date for every movie\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     release \u001b[38;5;241m=\u001b[39m my_driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.sc-f65f65be-0.ktSkVi ul.ipc-inline-list.ipc-inline-list--show-dividers.ipc-inline-list--inline.ipc-metadata-list-item__list-content.base a\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:426\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    423\u001b[0m         params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m    425\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_value(params)\n\u001b[0;32m--> 426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py:344\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[1;32m    343\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py:366\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    363\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 366\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/http/client.py:1344\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1344\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/http/client.py:307\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/http/client.py:268\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 268\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_data():\n",
    "    '''Scrapes all the data on any search result page (waits 3 seconds for page to load ). It gets all HTML (parent) elements with the 'h3' tag \n",
    "       and stores it in a variable 'header_', then a for-loop that gets the child element with tag \n",
    "       name 'a', and appends the text of the result to a list, 'title'. \n",
    "       The same is done for a second list 'title_element' which contains the 'href' attribute (link) to every title.\n",
    "       \n",
    "       Returns a dictionary with the 'Title' and the 'links'\n",
    "    ''' \n",
    "    \n",
    "    my_path = '/Users/macbookpro2018/data_science/web_scraping/IMDb'\n",
    "    my_file = 'imdb_feature_films.csv'\n",
    "    \n",
    "    \n",
    "\n",
    "    #Open search result page\n",
    "    page_one = my_driver.get(feature_films)\n",
    "    \n",
    "    \n",
    "    #get all header elements\n",
    "    #header_ = my_driver.find_elements(By.TAG_NAME,'h3')\n",
    "    \n",
    "    #Initialize empty lists for title and title links\n",
    "    global title_\n",
    "    global title_element\n",
    "    global release_date\n",
    "    global rating\n",
    "    global total_votes\n",
    "    global award_nom_wins\n",
    "    global country_of_origin\n",
    "    global directors\n",
    "    global df\n",
    "    df = pd.DataFrame()\n",
    "    title_ = []\n",
    "    title_element = []\n",
    "    release_date = []\n",
    "    rating = []\n",
    "    total_votes = []\n",
    "    award_nom_wins = []\n",
    "    country_of_origin = []\n",
    "    directors = []\n",
    "    \n",
    "    #Checks if the movie index on the results page. \n",
    "    #This solves the solves for th eerror produced when the script goes to the next page and the movie index is 101 instead of 1.\n",
    "    def check_remainder(movie_index): \n",
    "        the_remainder = movie_index%100 #Checks the remainder after dividing the movie index by 100\n",
    "        if movie_index == 0:\n",
    "            return 0 #Returns 0 if the movie index is 0\n",
    "        elif the_remainder == 0:\n",
    "            return 0 #Returns 0 if there is no remainder after dividing the movie index by 100\n",
    "        else:\n",
    "            return the_remainder #If there iis a remainder, retruns the remainder.\n",
    "        \n",
    "    #Get movie elemnts with tag_name 'a'\n",
    "    #loops through all elements in 'header_' and gets the titles\n",
    "    \n",
    "    start = 0 #Initialize this for the purpose of having a counter.\n",
    "    \n",
    "    for i in range(300): #Get only movie data from the first 300 movies on the search results page.\n",
    "        #my_driver.get(feature_films)\n",
    "        header = my_driver.find_elements(By.CSS_SELECTOR,'h3.lister-item-header')[check_remainder(i)]\n",
    "        if start == 300:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        #Checks if we are at the end of the page and need to click the next button or not.\n",
    "        if header.find_element(By.CSS_SELECTOR,'span').text.strip('.') == my_driver.find_element(By.XPATH,'//*[@id=\"main\"]/div/div[4]/span[1]').text.split(' ')[0].split('-')[1]:\n",
    "            \n",
    "            if my_driver.find_element(By.CSS_SELECTOR,'div.desc > a.lister-page-next.next-page').text not in my_driver.find_element(By.CSS_SELECTOR,'div.desc').text:\n",
    "                break\n",
    "                \n",
    "            else: \n",
    "                page_one = my_driver.find_element(By.PARTIAL_LINK_TEXT,'Next')\n",
    "                page_one.click()\n",
    "                time.sleep(4)\n",
    "                #header = my_driver.find_elements(By.CSS_SELECTOR,'h3.lister-item-header > a')\n",
    "                #title_.append(i.find_element(By.TAG_NAME,'a').text)\n",
    "                #title_element.append(i.find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "        else:\n",
    "            \n",
    "            title_.append(header.find_element(By.CSS_SELECTOR,'a').text) #appends the title to the global list above\n",
    "            title_element.append(header.find_element(By.CSS_SELECTOR,'a').get_attribute('href')) #appends the movie link to the global list above.\n",
    "            #print(title_,title_element)\n",
    "        \n",
    "        start += 1 #Incrementor for the counter\n",
    "\n",
    "    #Try to read the csv file to confirm if the file already exists in the folder.\n",
    "    try:\n",
    "        file_df = pd.read_csv(os.path.join(my_path,my_file))\n",
    "    #Create the file if it doesn't exist.    \n",
    "    except FileNotFoundError:\n",
    "        my_columns = ['Title','Link','Release Date','Rating','Total Votes','Awards Wins & Nominations','Country of Origin','Director']\n",
    "        file = open(os.path.join(my_path,my_file), 'a')\n",
    "        writer_object = csv.writer(file)\n",
    "        writer_object.writerow(my_columns)\n",
    "            \n",
    "        file.close() #close file after creating ad writing to it.\n",
    "    \n",
    "    for url in title_element: #Loop through the list of movie links collected\n",
    "        \n",
    "        file_df = pd.read_csv(os.path.join(my_path,my_file)) #Reads th csv file into a Pandas DataFrame\n",
    "        if url in file_df['Link']: #Checks if the movie url already exists in the 'Links' column\n",
    "            pass\n",
    "        else: #If the moie url does not exist in the csv file as per the check above\n",
    "        \n",
    "            #feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\n",
    "            #webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "            my_driver.get(url) #avigate to the movie url in the browser\n",
    "\n",
    "            #Get release date for the movie\n",
    "            release = my_driver.find_elements(By.CSS_SELECTOR,'div.sc-f65f65be-0.ktSkVi ul.ipc-inline-list.ipc-inline-list--show-dividers.ipc-inline-list--inline.ipc-metadata-list-item__list-content.base a')\n",
    "\n",
    "            #Get the ratings\n",
    "            rates = my_driver.find_element(By.CSS_SELECTOR, 'div.ipc-button__text > div.sc-f6306ea-3.loTxjn')\n",
    "\n",
    "            #Get award wins and Nominations\n",
    "            wins = my_driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[1]')\n",
    "\n",
    "\n",
    "            #Get the director of the movie\n",
    "            direct = my_driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[1]/div[3]/ul/li[1]/div')\n",
    "        \n",
    "        \n",
    "            #Appends the release date to the list above\n",
    "            release_date.append(release[0].text)\n",
    "\n",
    "\n",
    "            if rates.text == 'Rate':\n",
    "                #Appends NONE to the Rating list above\n",
    "                rating.append(None)\n",
    "            else:\n",
    "                #Appends the rates to the rating list above\n",
    "                rating.append(rates.text[:3])\n",
    "\n",
    "\n",
    "            #Appends the Total Votes for movies that have ratings\n",
    "            total_votes.append(rates.text[8:])\n",
    "\n",
    "            #Appends the country of Origin (Country where the movie was made in)\n",
    "            country_of_origin.append(release[1].text)\n",
    "\n",
    "\n",
    "            if 'Award' in wins.text:\n",
    "                #Appends the number of wins and awards to the 'award_nom_wins' list above\n",
    "                award_nom_wins.append(wins.text)\n",
    "            else:\n",
    "                #Appends NONE to the 'award_nom_wins' list above\n",
    "                award_nom_wins.append(None)\n",
    "\n",
    "\n",
    "            #Appends the directors to the 'Directors' list above\n",
    "            directors.append(direct[0].text)\n",
    "\n",
    "\n",
    "\n",
    "            new_entry = [title_[title_element.index(url)],title_element[title_element.index(url)],release_date[-1],rating[-1],total_votes[-1],award_nom_wins[-1],country_of_origin[-1],directors[-1]]\n",
    "            file_sec = open(os.path.join(my_path,my_file), 'a')\n",
    "            writer_object = csv.writer(file_sec)\n",
    "            writer_object.writerow(new_entry)\n",
    "\n",
    "            file_sec.close()\n",
    "         \n",
    "    #this is to actually return my complete dataframe\n",
    "    dickens = {'Title':title_, 'Link':title_element, 'Release Date':release_date,\n",
    "             'Rating':rating, 'Total Votes':total_votes, 'Awards Wins & Nominations':award_nom_wins,\n",
    "             'Country of Origin':country_of_origin, 'Director':directors}\n",
    "    dickens\n",
    "    df.from_dict(dickens)\n",
    "    return df\n",
    "\n",
    "#Run the Scrape Data function\n",
    "scrape_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b586f",
   "metadata": {},
   "source": [
    "# While the direction for analysis on this data is yet to be decided, the dataset is a very interestig one and there a lot of areas to go with this.\n",
    "\n",
    "## Updates will follow on what Insights I will like to glean form this dataset.\n",
    "#Anticipate!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f18f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
