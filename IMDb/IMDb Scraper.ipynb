{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb2ce90",
   "metadata": {},
   "source": [
    "# Ugwumsi Egbuna\n",
    "## Data Scientist\n",
    "## IMDb Web Scraper\n",
    "## March 11, 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c405e0",
   "metadata": {},
   "source": [
    "# This script scrapes data on movies from January 2000 to September 2022\n",
    "## It captures the following data points\n",
    "1. Movie Title\n",
    "2. Release Date\n",
    "3. Rating\n",
    "4. Total Number of votes in the rating\n",
    "5. Award Nomination Wins\n",
    "6. Country of Origin\n",
    "7. Directors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc9615",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418635c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928be6b3",
   "metadata": {},
   "source": [
    "Call Web Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22744585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|█████████████████| 8.84M/8.84M [00:01<00:00, 8.37MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Set up driver to automatically load chrome browser\n",
    "my_driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404b8ca",
   "metadata": {},
   "source": [
    "Navigate to the search results page on the IMDb website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5059c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get search result page\n",
    "feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\n",
    "\n",
    "#Open search result page\n",
    "my_driver.get(feature_films)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e8ba2",
   "metadata": {},
   "source": [
    "## The following steps were taken in this scraping exercise;\n",
    "1. Install and setup a chrome WebDriver, the lauch the chrome browser window.\n",
    "2. Navigate to the search results page.\n",
    "3. Extracts the movie titles and Movie Links on each page.\n",
    "4. Check if there are no more movies on the page and we need to go the next page to cotinue scraping.\n",
    "5. Loop through the url list from the movies gotten in 4 up.\n",
    "6. Navigate to the url in the browser, and get all the relevant details from there such as Directors, Award Wins, Ratings etc.\n",
    "7. Add them to their respective lists.\n",
    "8. Create a csv file in th epresent working directory and write all the data to the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97582174",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_data():\n",
    "    '''Scrapes all the data on any search result page (waits 3 seconds for page to load ). It gets all HTML (parent) elements with the 'h3' tag \n",
    "       and stores it in a variable 'header_', then a for-loop that gets the child element with tag \n",
    "       name 'a', and appends the text of the result to a list, 'title'. \n",
    "       The same is done for a second list 'title_element' which contains the 'href' attribute (link) to every title.\n",
    "       \n",
    "       Returns a dictionary with the 'Title' and the 'links'\n",
    "    ''' \n",
    "    \n",
    "    my_path = '/Users/macbookpro2018/data_science/web_scraping/IMDb'\n",
    "    my_file = 'imdb_feature_films.csv'\n",
    "    \n",
    "    \n",
    "\n",
    "    #Open search result page\n",
    "    page_one = my_driver.get(feature_films)\n",
    "    \n",
    "    \n",
    "    #get all header elements\n",
    "    #header_ = my_driver.find_elements(By.TAG_NAME,'h3')\n",
    "    \n",
    "    #Initialize empty lists for title and title links\n",
    "    global title_\n",
    "    global title_element\n",
    "    global release_date\n",
    "    global rating\n",
    "    global total_votes\n",
    "    global award_nom_wins\n",
    "    global country_of_origin\n",
    "    global directors\n",
    "    global df\n",
    "    df = pd.DataFrame()\n",
    "    title_ = []\n",
    "    title_element = []\n",
    "    release_date = []\n",
    "    rating = []\n",
    "    total_votes = []\n",
    "    award_nom_wins = []\n",
    "    country_of_origin = []\n",
    "    directors = []\n",
    "    \n",
    "    #Checks if the movie index on the results page. \n",
    "    #This solves the solves for th eerror produced when the script goes to the next page and the movie index is 101 instead of 1.\n",
    "    def check_remainder(movie_index): \n",
    "        the_remainder = movie_index%100 #Checks the remainder after dividing the movie index by 100\n",
    "        if movie_index == 0:\n",
    "            return 0 #Returns 0 if the movie index is 0\n",
    "        elif the_remainder == 0:\n",
    "            return 0 #Returns 0 if there is no remainder after dividing the movie index by 100\n",
    "        else:\n",
    "            return the_remainder #If there iis a remainder, retruns the remainder.\n",
    "        \n",
    "    #Get movie elemnts with tag_name 'a'\n",
    "    #loops through all elements in 'header_' and gets the titles\n",
    "    \n",
    "    start = 0 #Initialize this for the purpose of having a counter.\n",
    "    \n",
    "    for i in range(300): #Get only movie data from the first 300 movies on the search results page.\n",
    "        #my_driver.get(feature_films)\n",
    "        header = my_driver.find_elements(By.CSS_SELECTOR,'h3.lister-item-header')[check_remainder(i)]\n",
    "        if start == 300:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        #Checks if we are at the end of the page and need to click the next button or not.\n",
    "        if header.find_element(By.CSS_SELECTOR,'span').text.strip('.') == my_driver.find_element(By.XPATH,'//*[@id=\"main\"]/div/div[4]/span[1]').text.split(' ')[0].split('-')[1]:\n",
    "            \n",
    "            if my_driver.find_element(By.CSS_SELECTOR,'div.desc > a.lister-page-next.next-page').text not in my_driver.find_element(By.CSS_SELECTOR,'div.desc').text:\n",
    "                break\n",
    "                \n",
    "            else: \n",
    "                page_one = my_driver.find_element(By.PARTIAL_LINK_TEXT,'Next')\n",
    "                page_one.click()\n",
    "                time.sleep(4)\n",
    "                #header = my_driver.find_elements(By.CSS_SELECTOR,'h3.lister-item-header > a')\n",
    "                #title_.append(i.find_element(By.TAG_NAME,'a').text)\n",
    "                #title_element.append(i.find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "        else:\n",
    "            \n",
    "            title_.append(header.find_element(By.CSS_SELECTOR,'a').text) #appends the title to the global list above\n",
    "            title_element.append(header.find_element(By.CSS_SELECTOR,'a').get_attribute('href')) #appends the movie link to the global list above.\n",
    "            #print(title_,title_element)\n",
    "        \n",
    "        start += 1 #Incrementor for the counter\n",
    "\n",
    "    #Try to read the csv file to confirm if the file already exists in the folder.\n",
    "    try:\n",
    "        file_df = pd.read_csv(os.path.join(my_path,my_file))\n",
    "    #Create the file if it doesn't exist.    \n",
    "    except FileNotFoundError:\n",
    "        my_columns = ['Title','Link','Release Date','Rating','Total Votes','Awards Wins & Nominations','Country of Origin','Director']\n",
    "        file = open(os.path.join(my_path,my_file), 'a')\n",
    "        writer_object = csv.writer(file)\n",
    "        writer_object.writerow(my_columns)\n",
    "            \n",
    "        file.close() #close file after creating ad writing to it.\n",
    "    \n",
    "    for url in title_element: #Loop through the list of movie links collected\n",
    "        \n",
    "        file_df = pd.read_csv(os.path.join(my_path,my_file)) #Reads th csv file into a Pandas DataFrame\n",
    "        if url in file_df['Link']: #Checks if the movie url already exists in the 'Links' column\n",
    "            pass\n",
    "        else: #If the moie url does not exist in the csv file as per the check above\n",
    "        \n",
    "            #feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\n",
    "            #webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "            my_driver.get(url) #avigate to the movie url in the browser\n",
    "\n",
    "            #Get release date for the movie\n",
    "            release = my_driver.find_elements(By.CSS_SELECTOR,'div.sc-f65f65be-0.ktSkVi ul.ipc-inline-list.ipc-inline-list--show-dividers.ipc-inline-list--inline.ipc-metadata-list-item__list-content.base a')\n",
    "\n",
    "            #Get the ratings\n",
    "            rates = my_driver.find_element(By.CSS_SELECTOR, 'div.ipc-button__text > div.sc-f6306ea-3.loTxjn')\n",
    "\n",
    "            #Get award wins and Nominations\n",
    "            wins = my_driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[1]')\n",
    "\n",
    "\n",
    "            #Get the director of the movie\n",
    "            direct = my_driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[1]/div[3]/ul/li[1]/div')\n",
    "        \n",
    "        \n",
    "            #Appends the release date to the list above\n",
    "            release_date.append(release[0].text)\n",
    "\n",
    "\n",
    "            if rates.text == 'Rate':\n",
    "                #Appends NONE to the Rating list above\n",
    "                rating.append(None)\n",
    "            else:\n",
    "                #Appends the rates to the rating list above\n",
    "                rating.append(rates.text[:3])\n",
    "\n",
    "\n",
    "            #Appends the Total Votes for movies that have ratings\n",
    "            total_votes.append(rates.text[8:])\n",
    "\n",
    "            #Appends the country of Origin (Country where the movie was made in)\n",
    "            country_of_origin.append(release[1].text)\n",
    "\n",
    "\n",
    "            if 'Award' in wins.text:\n",
    "                #Appends the number of wins and awards to the 'award_nom_wins' list above\n",
    "                award_nom_wins.append(wins.text)\n",
    "            else:\n",
    "                #Appends NONE to the 'award_nom_wins' list above\n",
    "                award_nom_wins.append(None)\n",
    "\n",
    "\n",
    "            #Appends the directors to the 'Directors' list above\n",
    "            directors.append(direct[0].text)\n",
    "\n",
    "\n",
    "\n",
    "            new_entry = [title_[title_element.index(url)],title_element[title_element.index(url)],release_date[-1],rating[-1],total_votes[-1],award_nom_wins[-1],country_of_origin[-1],directors[-1]]\n",
    "            file_sec = open(os.path.join(my_path,my_file), 'a')\n",
    "            writer_object = csv.writer(file_sec)\n",
    "            writer_object.writerow(new_entry)\n",
    "\n",
    "            file_sec.close()\n",
    "         \n",
    "    #this is to actually return my complete dataframe\n",
    "    dickens = {'Title':title_, 'Link':title_element, 'Release Date':release_date,\n",
    "             'Rating':rating, 'Total Votes':total_votes, 'Awards Wins & Nominations':award_nom_wins,\n",
    "             'Country of Origin':country_of_origin, 'Director':directors}\n",
    "    dickens\n",
    "    df.from_dict(dickens)\n",
    "    return df\n",
    "\n",
    "#Run the Scrape Data function\n",
    "#scrape_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099bf93",
   "metadata": {},
   "source": [
    "# While the direction for analysis on this data is yet to be decided, the dataset is a very interestig one and there a lot of areas to go with this.\n",
    "\n",
    "## Updates will follow on what Insights I will like to glean form this dataset.\n",
    "#Anticipate!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
