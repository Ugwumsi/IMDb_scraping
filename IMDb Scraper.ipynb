{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418635c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928be6b3",
   "metadata": {},
   "source": [
    "Call Driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22744585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|█████████████████| 8.15M/8.15M [00:03<00:00, 2.42MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Set up driver to automatically load chrome browser\n",
    "my_driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5059c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get search result page\n",
    "feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\n",
    "\n",
    "#Open search result page\n",
    "my_driver.get(feature_films)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e8ba2",
   "metadata": {},
   "source": [
    "# Main Code Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97582174",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id\nStacktrace:\n0   chromedriver                        0x000000010f8dd788 chromedriver + 4515720\n1   chromedriver                        0x000000010f8619d3 chromedriver + 4008403\n2   chromedriver                        0x000000010f4f3feb chromedriver + 413675\n3   chromedriver                        0x000000010f51e2fb chromedriver + 586491\n4   chromedriver                        0x000000010f5486dc chromedriver + 759516\n5   chromedriver                        0x000000010f54648d chromedriver + 750733\n6   chromedriver                        0x000000010f545bdb chromedriver + 748507\n7   chromedriver                        0x000000010f4cce6a chromedriver + 253546\n8   chromedriver                        0x000000010f8ad6cd chromedriver + 4318925\n9   chromedriver                        0x000000010f8b1f35 chromedriver + 4337461\n10  chromedriver                        0x000000010f8b91ff chromedriver + 4366847\n11  chromedriver                        0x000000010f8b2c5a chromedriver + 4340826\n12  chromedriver                        0x000000010f888c2c chromedriver + 4168748\n13  chromedriver                        0x000000010f4cbea0 chromedriver + 249504\n14  dyld                                0x000000011c08452e start + 462\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 219\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m#Run the Scrape Data function\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m \u001b[43mscrape_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [67], line 31\u001b[0m, in \u001b[0;36mscrape_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m my_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_feature_films.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#Open search result page\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m page_one \u001b[38;5;241m=\u001b[39m \u001b[43mmy_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_films\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#get all header elements\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#header_ = my_driver.find_elements(By.TAG_NAME,'h3')\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#Initialize empty lists for title and title links\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m title_\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[1;32m    430\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mInvalidSessionIdException\u001b[0m: Message: invalid session id\nStacktrace:\n0   chromedriver                        0x000000010f8dd788 chromedriver + 4515720\n1   chromedriver                        0x000000010f8619d3 chromedriver + 4008403\n2   chromedriver                        0x000000010f4f3feb chromedriver + 413675\n3   chromedriver                        0x000000010f51e2fb chromedriver + 586491\n4   chromedriver                        0x000000010f5486dc chromedriver + 759516\n5   chromedriver                        0x000000010f54648d chromedriver + 750733\n6   chromedriver                        0x000000010f545bdb chromedriver + 748507\n7   chromedriver                        0x000000010f4cce6a chromedriver + 253546\n8   chromedriver                        0x000000010f8ad6cd chromedriver + 4318925\n9   chromedriver                        0x000000010f8b1f35 chromedriver + 4337461\n10  chromedriver                        0x000000010f8b91ff chromedriver + 4366847\n11  chromedriver                        0x000000010f8b2c5a chromedriver + 4340826\n12  chromedriver                        0x000000010f888c2c chromedriver + 4168748\n13  chromedriver                        0x000000010f4cbea0 chromedriver + 249504\n14  dyld                                0x000000011c08452e start + 462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "# #Set up driver to automatically load chrome browser\n",
    "# my_driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "\n",
    "# #Get search result page\n",
    "# feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\n",
    "\n",
    "# #Open search result page\n",
    "# my_driver.get(feature_films)\n",
    "\n",
    "def scrape_data():\n",
    "    '''Scrapes all the data on any search result page (waits 3 seconds for page to load ). It gets all HTML (parent) elements with the 'h3' tag \n",
    "       and stores it in a variable 'header_', then a for-loop that gets the child element with tag \n",
    "       name 'a', and appends the text of the result to a list, 'title'. \n",
    "       The same is done for a second list 'title_element' which contains the 'href' attribute (link) to every title.\n",
    "       \n",
    "       Returns a dictionary with the 'Title' and the 'links'\n",
    "    ''' \n",
    "    \n",
    "    my_path = '/Users/macbookpro2018/data_science/web_scraping'\n",
    "    my_file = 'imdb_feature_films.csv'\n",
    "    \n",
    "    \n",
    "\n",
    "    #Open search result page\n",
    "    page_one = my_driver.get(feature_films)\n",
    "    \n",
    "    \n",
    "    #get all header elements\n",
    "    #header_ = my_driver.find_elements(By.TAG_NAME,'h3')\n",
    "    \n",
    "    #Initialize empty lists for title and title links\n",
    "    global title_\n",
    "    global title_element\n",
    "    global release_date\n",
    "    global rating\n",
    "    global total_votes\n",
    "    global award_nom_wins\n",
    "    global country_of_origin\n",
    "    global directors\n",
    "    global df\n",
    "    df = pd.DataFrame()\n",
    "    title_ = []\n",
    "    title_element = []\n",
    "    release_date = []\n",
    "    rating = []\n",
    "    total_votes = []\n",
    "    award_nom_wins = []\n",
    "    country_of_origin = []\n",
    "    directors = []\n",
    "    \n",
    "    \n",
    "    def bitch_nigga(num):\n",
    "        the_nigga = num%100\n",
    "        if num == 0:\n",
    "            return 0\n",
    "        elif the_nigga == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return the_nigga\n",
    "    #Get movie elemnts with tag_name 'a'\n",
    "    #loops through all elements in 'header_' and gets the titles\n",
    "    start = 0\n",
    "    for i in range(300):\n",
    "        #my_driver.get(feature_films)\n",
    "        header = my_driver.find_elements(By.CSS_SELECTOR,'h3.lister-item-header')[bitch_nigga(i)]\n",
    "        if start == 300:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        print('Hello')\n",
    "        \n",
    "        \n",
    "        if header.find_element(By.CSS_SELECTOR,'span').text.strip('.') == my_driver.find_element(By.XPATH,'//*[@id=\"main\"]/div/div[4]/span[1]').text.split(' ')[0].split('-')[1]:\n",
    "            if my_driver.find_element(By.CSS_SELECTOR,'div.desc > a.lister-page-next.next-page').text not in my_driver.find_element(By.CSS_SELECTOR,'div.desc').text:\n",
    "                break\n",
    "            else:\n",
    "                page_one = my_driver.find_element(By.PARTIAL_LINK_TEXT,'Next')\n",
    "                page_one.click()\n",
    "                time.sleep(4)\n",
    "                #header = my_driver.find_elements(By.CSS_SELECTOR,'h3.lister-item-header > a')\n",
    "                #title_.append(i.find_element(By.TAG_NAME,'a').text)\n",
    "                #title_element.append(i.find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "        else:\n",
    "#             print('before Nums')\n",
    "#             #nums = header_.find_element(By.CSS_SELECTOR,'h3.lister-item-header > span.lister-item-index.unbold.text-primary').text.strip('.')\n",
    "#             print('After Nums')\n",
    "#             page_in = my_driver.find_element(By.XPATH,'//*[@id=\"main\"]/div/div[4]/span[1]').text.split(' ')[0].split('-')[1]\n",
    "#             print('After Page Index')\n",
    "#             pg_bottom = my_driver.find_element(By.CSS_SELECTOR,'div.desc').text\n",
    "#             print('After Page Bottom')\n",
    "#             next_button = my_driver.find_element(By.CSS_SELECTOR,'div.desc > a.lister-page-next.next-page').text\n",
    "#             print('After Next Button')\n",
    "            title_.append(header.find_element(By.CSS_SELECTOR,'a').text)\n",
    "            title_element.append(header.find_element(By.CSS_SELECTOR,'a').get_attribute('href'))\n",
    "            #print(title_,title_element)\n",
    "        print(start)\n",
    "        start += 1\n",
    "            \n",
    "    for url in title_element:\n",
    "\n",
    "        #feature_films = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2022-09-14&count=100'\n",
    "        #webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        my_driver.get(url)\n",
    "      \n",
    "        #Get release date for every movie\n",
    "        release = my_driver.find_elements(By.CSS_SELECTOR,'div.sc-f65f65be-0.ktSkVi ul.ipc-inline-list.ipc-inline-list--show-dividers.ipc-inline-list--inline.ipc-metadata-list-item__list-content.base a')\n",
    "        \n",
    "        #Get the ratings\n",
    "        rates = my_driver.find_element(By.CSS_SELECTOR, 'div.ipc-button__text > div.sc-f6306ea-3.loTxjn')\n",
    "        \n",
    "        #Get award wins and Nominations\n",
    "        wins = my_driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[1]')\n",
    "        \n",
    "        \n",
    "        #Get the director of each movie\n",
    "        direct = my_driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[1]/div[3]/ul/li[1]/div')\n",
    "        \n",
    "        try:\n",
    "            file_df = pd.read_csv(os.path.join(my_path,my_file))\n",
    "            if url in file_df['Link']:\n",
    "                pass\n",
    "            else:\n",
    "                #Appends the release date to the list above\n",
    "                release_date.append(release[0].text)\n",
    "\n",
    "\n",
    "                if rates.text == 'Rate':\n",
    "                    #Appends NONE to the Rating list above\n",
    "                    rating.append(None)\n",
    "                else:\n",
    "                    #Appends the rates to the rating list above\n",
    "                    rating.append(rates.text[:3])\n",
    "\n",
    "\n",
    "                #Appends the Total Votes for movies that have ratings\n",
    "                total_votes.append(rates.text[8:])\n",
    "\n",
    "                #Appends the country of Origin (Country where the movie was made in)\n",
    "                country_of_origin.append(release[1].text)\n",
    "\n",
    "\n",
    "                if 'Award' in wins.text:\n",
    "                    #Appends the number of wins and awards to the 'award_nom_wins' list above\n",
    "                    award_nom_wins.append(wins.text)\n",
    "                else:\n",
    "                    #Appends NONE to the 'award_nom_wins' list above\n",
    "                    award_nom_wins.append(None)\n",
    "\n",
    "\n",
    "                #Appends the directors to the 'Directors' list above\n",
    "                directors.append(direct[0].text)\n",
    "                \n",
    "                \n",
    "                \n",
    "                new_entry = [title_.index(title_element.index(url)),title_element[title_element.index(url)],release_date[-1],rating[-1],total_votes[-1],award_nom_wins[-1],country_of_origin[-1],directors[-1]]\n",
    "                file = open(os.path.join(my_path,my_file), 'a')\n",
    "                file.write(new_entry)\n",
    "                file.close()\n",
    "        except FileNotFoundError:\n",
    "            \n",
    "            #Appends the release date to the list above\n",
    "            release_date.append(release[0].text)\n",
    "\n",
    "\n",
    "            if rates.text == 'Rate':\n",
    "                #Appends NONE to the Rating list above\n",
    "                rating.append(None)\n",
    "            else:\n",
    "                #Appends the rates to the rating list above\n",
    "                rating.append(rates.text[:3])\n",
    "\n",
    "\n",
    "            #Appends the Total Votes for movies that have ratings\n",
    "            total_votes.append(rates.text[8:])\n",
    "\n",
    "            #Appends the country of Origin (Country where the movie was made in)\n",
    "            country_of_origin.append(release[1].text)\n",
    "\n",
    "\n",
    "            if 'Award' in wins.text:\n",
    "                #Appends the number of wins and awards to the 'award_nom_wins' list above\n",
    "                award_nom_wins.append(wins.text)\n",
    "            else:\n",
    "                #Appends NONE to the 'award_nom_wins' list above\n",
    "                award_nom_wins.append(None)\n",
    "\n",
    "\n",
    "            #Appends the directors to the 'Directors' list above\n",
    "            directors.append(direct[0].text)\n",
    "\n",
    "\n",
    "\n",
    "            new_entry = [title_[title_element.index(url)],title_element[title_element.index(url)],release_date[-1],rating[-1],total_votes[-1],award_nom_wins[-1],country_of_origin[-1],directors[-1]]\n",
    "\n",
    "            file = open(os.path.join(my_path,my_file), 'w')\n",
    "            file.write(new_entry)\n",
    "            file.close()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    #this is to actually return my complete dataframe\n",
    "    dickens = {'Title':title_, 'Link':title_element, 'Release Date':release_date,\n",
    "             'Rating':rating, 'Total Votes':total_votes, 'Awards Wins & Nominations':award_nom_wins,\n",
    "             'Country of Origin':country_of_origin, 'Director':directors}\n",
    "    dickens\n",
    "    df.from_dict(dickens)\n",
    "    return df\n",
    "\n",
    "#Run the Scrape Data function\n",
    "scrape_data()\n",
    "\n",
    "\n",
    "# my_path = '/Users/macbookpro2018/data_science/web_scraping'\n",
    "# my_file = 'imdb_feature_films.csv'\n",
    "\n",
    "\n",
    "# if os.getcwd() == my_path:\n",
    "#     if os.path.exists(my_file):\n",
    "#         file_df = pd.read_csv(my_file, keep_default_na=False)\n",
    "#         with open(my_file, 'a+') as file:\n",
    "            \n",
    "#             for i in df[\"Link\"]:\n",
    "#                 if i in file_df['Link']:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     os.SEEK_END()\n",
    "#                     file.write('\\n')\n",
    "#                     file.write(df.loc[df['Link'] == i])\n",
    "#                     file.close()\n",
    "        \n",
    "#     else:\n",
    "#         df.to_csv('imdb_feature_films.csv')\n",
    "# else:\n",
    "#     os.chdir(my_path)\n",
    "#     if os.path.exists(my_file):\n",
    "#         file_df = pd.read_csv(my_file, keep_default_na=False)\n",
    "#         with open(my_file, 'a+') as file:\n",
    "            \n",
    "#             for i in df['Link']:\n",
    "#                 if i in file_df['Link']:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     os.SEEK_END()\n",
    "#                     file.write('\\n')\n",
    "#                     file.write(df.loc[df['Link'] == i])\n",
    "#                     file.close()\n",
    "#     else:\n",
    "#         df.to_csv('imdb_feature_films.csv')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b465b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global adf\n",
    "adf = pd.DataFrame()\n",
    "my_dict = {'First':['Nonso','Ugwumsi','Chisimdi'],'Middle':['Emmanuel','Tochukwu','Chiamaka']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb814869",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m title_element[title_element\u001b[38;5;241m.\u001b[39mindex(\u001b[43murl\u001b[49m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "title_element[title_element.index(url)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07fec673",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 1\n",
    "two = 2\n",
    "three = 3\n",
    "four = 4\n",
    "five = 5\n",
    "six = 6\n",
    "\n",
    "ahs = pd.DataFrame([one,two,three,four,five,six])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8bec91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  4\n",
       "4  5\n",
       "5  6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ahs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd8684ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'our_life.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mour_life.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/data_science/web_scraping/ws_venv/lib/python3.8/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'our_life.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('our_life.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a657b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
